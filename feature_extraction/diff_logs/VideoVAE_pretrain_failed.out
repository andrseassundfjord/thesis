Started: VideoVAE_full_no_pretrain, Augmented run
Using device: cuda
Model: VideoVAE
Number of parameters in model:  178732681
torch.cuda.memory_allocated: 0.671265GB
torch.cuda.memory_reserved: 0.695312GB
torch.cuda.max_memory_reserved: 0.695312GB
Start training
Time taken: 999.14 seconds
Epoch: 9 	 Train Loss: 83905.571990	 Test Loss: 81835.023765
Time taken: 1979.17 seconds
Epoch: 19 	 Train Loss: 69211.513785	 Test Loss: 64920.628704
Time taken: 2954.32 seconds
Epoch: 29 	 Train Loss: 57127.057339	 Test Loss: 53632.556173
Time taken: 3926.93 seconds
Epoch: 39 	 Train Loss: 53753.178410	 Test Loss: 49411.018596
Time taken: 4892.86 seconds
Epoch: 49 	 Train Loss: 51874.349227	 Test Loss: 48205.316049
Time taken: 5858.44 seconds
Epoch: 59 	 Train Loss: 50292.391383	 Test Loss: 47610.597454
Time taken: 6823.54 seconds
Epoch: 69 	 Train Loss: 48622.211308	 Test Loss: 44642.361613
Time taken: 7788.00 seconds
Epoch: 79 	 Train Loss: 47130.643314	 Test Loss: 44200.151466
Time taken: 8752.73 seconds
Epoch: 89 	 Train Loss: 45906.794586	 Test Loss: 42270.331366
Time taken: 9712.92 seconds
Epoch: 99 	 Train Loss: 45112.612014	 Test Loss: 42605.928974
Time taken: 10675.53 seconds
Epoch: 109 	 Train Loss: 44629.259290	 Test Loss: 44632.624190
Time taken: 11638.84 seconds
Epoch: 119 	 Train Loss: 44520.385056	 Test Loss: 42291.024807
Time taken: 12601.15 seconds
Epoch: 129 	 Train Loss: 44549.473928	 Test Loss: 42346.531019
Time taken: 13563.38 seconds
Epoch: 139 	 Train Loss: 44271.647942	 Test Loss: 41971.624383
Time taken: 14526.74 seconds
Epoch: 149 	 Train Loss: 44533.375533	 Test Loss: 42576.927701
Finished training
Time taken: 14526.74 seconds
Best test loss: 40889.254938 at epoch: 142
Video loss: 153218.56261574075, at epoch: 142
Timeseries MAPE: 0.000000
Video MAPE: 5.363276
Started
Traceback (most recent call last):
  File "run_MVAE_augmented.py", line 507, in <module>
    split_size = split_size
  File "/work6/a_sundfjord/thesis/feature_extraction/clustering.py", line 215, in run_clustering
    latents, labels, model_name = get_latent(model, latent_dim, hidden_layers, split_size)
  File "/work6/a_sundfjord/thesis/feature_extraction/clustering.py", line 154, in get_latent
    model.load_state_dict(torch.load(f'augmented_models/{model_name}_state.pth'))
  File "/work6/a_sundfjord/thesis/env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1671, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for VideoVAE:
	size mismatch for video_encoder.fc_mu.weight: copying a param with shape torch.Size([32, 512]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for video_encoder.fc_mu.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for video_encoder.fc_log_var.weight: copying a param with shape torch.Size([32, 512]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for video_encoder.fc_log_var.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for video_decoder.model.0.weight: copying a param with shape torch.Size([512, 32]) from checkpoint, the shape in current model is torch.Size([512, 512]).
